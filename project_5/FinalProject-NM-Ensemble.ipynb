{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sahil Kumar\\.conda\\envs\\ml\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\Sahil Kumar\\.conda\\envs\\ml\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\Sahil Kumar\\.conda\\envs\\ml\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loading completed. This dataset contains 3198 rows and 12 columns.\n",
      "Input Shape (2558, 10)\n",
      "Output Shape (640, 10)\n",
      "Number of Features 2558\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def load_csv_data(file_url):\n",
    "    return pd.read_csv(file_url)\n",
    "\n",
    "# PROGRAM EXECUTION\n",
    "try:\n",
    "    # It will read the CSV file from the given URL and convert it into Data Frame.\n",
    "    df_main = load_csv_data(\"allwine.csv\")\n",
    "    print(f\"Data Loading completed. This dataset contains {len(df_main)} rows and {len(df_main.columns)} columns.\")\n",
    "    features = ['fixed acidity', 'volatile acidity', 'citric acid',\n",
    "       'residual sugar', 'chlorides', 'free sulfur dioxide', 'density', 'pH',\n",
    "        'sulphates', 'alcohol']\n",
    "    target_variable = 'quality'\n",
    "\n",
    "    df = df_main[features]\n",
    "    target_df = df_main[target_variable]\n",
    "\n",
    "    # Apply standard scaler\n",
    "    scaler = StandardScaler()\n",
    "    inp_df = scaler.fit_transform(df)\n",
    "\n",
    "    # Split the data into features (X) and target variable (y)\n",
    "    X = inp_df\n",
    "    y = target_df\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    y_train = y_train.values\n",
    "    y_test = y_test.values\n",
    "\n",
    "    print('Input Shape', (X_train.shape))\n",
    "    print('Output Shape', X_test.shape)\n",
    "\n",
    "    num_of_features = X_train.shape[0]\n",
    "    print('Number of Features', num_of_features)\n",
    "\n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A THOUSAND TRIALS LATER >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thetas=> (10, 1) (10, 1) (10, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid_activation(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def cost(predictions_M, predictions_L, predictions_R, y):\n",
    "        pred = (predictions_L ** y) * ((((1 - predictions_L) ** (1 - y)) * predictions_M)) + (\n",
    "                (predictions_R ** y) * ((1 - predictions_R) ** (1 - y)) * (1 - predictions_M))\n",
    "        cost = -np.log(pred)\n",
    "        return cost\n",
    "\n",
    "def initialize_parameters(input_size):\n",
    "    w = np.random.randn(input_size, 1)\n",
    "    b = 0\n",
    "    return w, b\n",
    "\n",
    "def model_optimize(X, y, learning_rate, num_iterations):\n",
    "    m = X.shape[0]\n",
    "    input_size = X.shape[1]\n",
    "\n",
    "    # Initialize parameters for LR_middle\n",
    "    w_middle, b_middle = initialize_parameters(input_size)\n",
    "    \n",
    "    # Initialize parameters for LR_left\n",
    "    w_left, b_left = initialize_parameters(input_size)\n",
    "    \n",
    "    # Initialize parameters for LR_right\n",
    "    w_right, b_right = initialize_parameters(input_size)\n",
    "\n",
    "    costs = []\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        # Forward pass\n",
    "        linear_pred_M = np.dot(X, w_middle) + b_middle\n",
    "        predictions_M = sigmoid_activation(linear_pred_M)\n",
    "\n",
    "        linear_pred_L = np.dot(X, w_left) + b_left\n",
    "        predictions_L = sigmoid_activation(linear_pred_L)\n",
    "\n",
    "        linear_pred_R = np.dot(X, w_right) + b_right\n",
    "        predictions_R = sigmoid_activation(linear_pred_R)\n",
    "\n",
    "        # Calculate cost\n",
    "        current_cost = cost(predictions_M, predictions_L, predictions_R, y)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            costs.append(current_cost)\n",
    "\n",
    "        # Calculate derivatives\n",
    "        # Derivatives for LR_Middle\n",
    "        dL_dw_M = np.dot(X.T, (predictions_M - y))\n",
    "        dL_db_M = np.sum(predictions_M - y)\n",
    "\n",
    "        # Derivatives for LR_Left\n",
    "        dL_dw_L = np.dot(X.T, (predictions_L - y))\n",
    "        dL_db_L = np.sum(predictions_L - y)\n",
    "\n",
    "        # Derivatives for LR_Right\n",
    "        dL_dw_R = np.dot(X.T, (predictions_R - y))\n",
    "        dL_db_R = np.sum(predictions_R - y)\n",
    "\n",
    "        # # Update parameters using the learning rate\n",
    "        # # w_middle -= (learning_rate / m) * dL_dw_M[:, np.newaxis]\n",
    "        # w_middle -= (learning_rate / m) * dL_dw_M.reshape(-1, 1)\n",
    "        # b_middle -= (learning_rate / m) * dL_db_M\n",
    "        \n",
    "        # # w_left -= (learning_rate / m) * dL_dw_L[:, np.newaxis]\n",
    "        # w_left -= (learning_rate / m) * dL_dw_L.reshape(-1, 1)\n",
    "        # b_left -= (learning_rate / m) * dL_db_L\n",
    "        \n",
    "        # # w_right -= (learning_rate / m) * dL_dw_R[:, np.newaxis]\n",
    "        # w_right -= (learning_rate / m) * dL_dw_R.reshape(-1, 1)\n",
    "        # b_right -= (learning_rate / m) * dL_db_R\n",
    "        \n",
    "        # Update parameters using the learning rate\n",
    "                # Update parameters using the learning rate\n",
    "        w_middle -= (learning_rate / m) * np.mean(dL_dw_M.T, axis=0).reshape(-1, 1)\n",
    "        b_middle -= (learning_rate / m) * dL_db_M\n",
    "\n",
    "        w_left -= (learning_rate / m) * np.mean(dL_dw_L.T, axis=0).reshape(-1, 1)\n",
    "        b_left -= (learning_rate / m) * dL_db_L\n",
    "\n",
    "        w_right -= (learning_rate / m) * np.mean(dL_dw_R.T, axis=0).reshape(-1, 1)\n",
    "        b_right -= (learning_rate / m) * dL_db_R\n",
    "\n",
    "\n",
    "    return w_middle, b_middle, w_left, b_left, w_right, b_right, current_cost\n",
    "\n",
    "\n",
    "\n",
    "def conditional_probability_1(h_theta_L, h_theta_M, h_theta_R):\n",
    "    \"\"\"\n",
    "    Calculate the conditional probability P(1 | h_theta_L, h_theta_M, h_theta_R).\n",
    "\n",
    "    Parameters:\n",
    "    - h_theta_L: Output of LR_Left (sigmoid activation)\n",
    "    - h_theta_M: Output of LR_Middle (sigmoid activation)\n",
    "    - h_theta_R: Output of LR_Right (sigmoid activation)\n",
    "\n",
    "    Returns:\n",
    "    - Probability of class 1 given sigmoid outputs h_theta_L, h_theta_M, h_theta_R\n",
    "    \"\"\"\n",
    "    probability_1 = h_theta_L * h_theta_M + h_theta_R * (1 - h_theta_M)\n",
    "    return probability_1\n",
    "\n",
    "\n",
    "def conditional_probability_0(h_theta_L, h_theta_M, h_theta_R):\n",
    "    \"\"\"\n",
    "    Calculate the conditional probability P(0 | h_theta_L, h_theta_M, h_theta_R).\n",
    "\n",
    "    Parameters:\n",
    "    - h_theta_L: Output of LR_Left (sigmoid activation)\n",
    "    - h_theta_M: Output of LR_Middle (sigmoid activation)\n",
    "    - h_theta_R: Output of LR_Right (sigmoid activation)\n",
    "\n",
    "    Returns:\n",
    "    - Probability of class 0 given sigmoid outputs h_theta_L, h_theta_M, h_theta_R\n",
    "    \"\"\"\n",
    "    probability_0 = (1 - h_theta_L) * h_theta_M + (1 - h_theta_R) * (1 - h_theta_M)\n",
    "    return probability_0\n",
    "\n",
    "# Set hyperparameters\n",
    "learning_rate = 0.009\n",
    "num_iterations = 100\n",
    "\n",
    "# Train the model\n",
    "input_size = X_train.shape[1]\n",
    "w_middle, b_middle, w_left, b_left, w_right, b_right, current_cost = model_optimize(X_train, y_train, learning_rate, num_iterations)\n",
    "\n",
    "print(\"thetas=>\", w_middle.shape, w_left.shape, w_right.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Retrain the model using scaled data\n",
    "w_middle, b_middle, w_left, b_left, w_right, b_right, current_cost = model_optimize(X_train_scaled, y_train, learning_rate, num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification Result: True\n",
      "10\n",
      "640\n",
      "Training Accuracy: 0.5009375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def predict(w_middle, w_left, w_right):\n",
    "    # Calculate probabilities for both classes\n",
    "    probability_1 = conditional_probability_1(w_left,w_middle,w_right)\n",
    "    probability_0 = conditional_probability_0(w_left,w_middle,w_right)\n",
    "\n",
    "    # Verify the property P(1|xi,θM,θL,θR) + P(0|xi,θM,θL,θR) = 1\n",
    "    verification_result = np.allclose(probability_1 + probability_0, 1)\n",
    "\n",
    "    # Print the verification result\n",
    "    print(\"Verification Result:\", verification_result)\n",
    "\n",
    "    \n",
    "    # Make predictions based on probabilities\n",
    "    predictions = np.where(probability_1 > probability_0, 1, 0)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Assuming you have ground truth labels for your training data (y_train)\n",
    "predictions_train = predict(w_middle, w_left, w_right)\n",
    "\n",
    "print(len(predictions_train))\n",
    "print(len(X_test))\n",
    "\n",
    "# Compare predictions with actual labels\n",
    "accuracy_train = np.mean(predictions_train == y_test)\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification Result: True\n",
      "10\n",
      "640\n",
      "Training Accuracy: 0.50375\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid_activation(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def cost(predictions_M, predictions_L, predictions_R, y):\n",
    "    pred = (predictions_L ** y) * ((((1 - predictions_L) ** (1 - y)) * predictions_M)) + (\n",
    "        (predictions_R ** y) * ((1 - predictions_R) ** (1 - y)) * (1 - predictions_M))\n",
    "    cost = -np.log(pred)\n",
    "    return cost\n",
    "\n",
    "def initialize_parameters(input_size):\n",
    "    w = np.random.randn(input_size, 1)\n",
    "    b = 0\n",
    "    return w, b\n",
    "\n",
    "def model_optimize(X, y, learning_rate, num_iterations):\n",
    "    m = X.shape[0]\n",
    "    input_size = X.shape[1]\n",
    "\n",
    "    w_middle, b_middle = initialize_parameters(input_size)\n",
    "    w_left, b_left = initialize_parameters(input_size)\n",
    "    w_right, b_right = initialize_parameters(input_size)\n",
    "\n",
    "    costs = []\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        linear_pred_M = np.dot(X, w_middle) + b_middle\n",
    "        predictions_M = sigmoid_activation(linear_pred_M)\n",
    "\n",
    "        linear_pred_L = np.dot(X, w_left) + b_left\n",
    "        predictions_L = sigmoid_activation(linear_pred_L)\n",
    "\n",
    "        linear_pred_R = np.dot(X, w_right) + b_right\n",
    "        predictions_R = sigmoid_activation(linear_pred_R)\n",
    "\n",
    "        current_cost = cost(predictions_M, predictions_L, predictions_R, y)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            costs.append(current_cost)\n",
    "\n",
    "        dL_dw_M = np.dot(X.T, (predictions_M - y))\n",
    "        dL_db_M = np.sum(predictions_M - y)\n",
    "\n",
    "        dL_dw_L = np.dot(X.T, (predictions_L - y))\n",
    "        dL_db_L = np.sum(predictions_L - y)\n",
    "\n",
    "        dL_dw_R = np.dot(X.T, (predictions_R - y))\n",
    "        dL_db_R = np.sum(predictions_R - y)\n",
    "\n",
    "        w_middle -= (learning_rate / m) * np.mean(dL_dw_M.T, axis=0).reshape(-1, 1)\n",
    "        b_middle -= (learning_rate / m) * dL_db_M\n",
    "\n",
    "        w_left -= (learning_rate / m) * np.mean(dL_dw_L.T, axis=0).reshape(-1, 1)\n",
    "        b_left -= (learning_rate / m) * dL_db_L\n",
    "\n",
    "        w_right -= (learning_rate / m) * np.mean(dL_dw_R.T, axis=0).reshape(-1, 1)\n",
    "        b_right -= (learning_rate / m) * dL_db_R\n",
    "\n",
    "    return w_middle, b_middle, w_left, b_left, w_right, b_right, costs\n",
    "\n",
    "\n",
    "def predict(w_middle, w_left, w_right):\n",
    "    probability_1 = w_left * w_middle + w_right * (1 - w_middle)\n",
    "    probability_0 = (1 - w_left) * w_middle + (1 - w_right) * (1 - w_middle)\n",
    "    predictions = np.where(probability_1 > probability_0, 1, 0)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Assuming you have ground truth labels for your training data (y_train) and test data (X_test, y_test)\n",
    "# Set hyperparameters\n",
    "learning_rate = 0.01\n",
    "num_iterations = 1000\n",
    "\n",
    "# Assuming X_train, y_train, X_test, and y_test are defined\n",
    "input_size = X_train.shape[1]\n",
    "w_middle, b_middle, w_left, b_left, w_right, b_right, costs = model_optimize(X_train, y_train, learning_rate, num_iterations)\n",
    "\n",
    "\n",
    "def predict(w_middle, w_left, w_right):\n",
    "    # Calculate probabilities for both classes\n",
    "    probability_1 = conditional_probability_1(w_left,w_middle,w_right)\n",
    "    probability_0 = conditional_probability_0(w_left,w_middle,w_right)\n",
    "\n",
    "    # Verify the property P(1|xi,θM,θL,θR) + P(0|xi,θM,θL,θR) = 1\n",
    "    verification_result = np.allclose(probability_1 + probability_0, 1)\n",
    "\n",
    "    # Print the verification result\n",
    "    print(\"Verification Result:\", verification_result)\n",
    "\n",
    "    \n",
    "    # Make predictions based on probabilities\n",
    "    predictions = np.where(probability_1 > probability_0, 1, 0)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Assuming you have ground truth labels for your training data (y_train)\n",
    "predictions_train = predict(w_middle, w_left, w_right)\n",
    "\n",
    "print(len(predictions_train))\n",
    "print(len(X_test))\n",
    "\n",
    "# Compare predictions with actual labels\n",
    "accuracy_train = np.mean(predictions_train == y_test)\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
